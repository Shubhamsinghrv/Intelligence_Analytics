{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "30691339-206e-45e9-af3e-1a5ef9244081",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneDNN enabled: \n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"OneDNN enabled:\", tf.config.optimizer.get_jit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a02cf17d-b916-4771-a0a5-24cf9e9651f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow running on: CPU\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"  # Force CPU usage\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  # Suppress INFO and WARNING messages\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow running on:\", \"GPU\" if tf.config.list_physical_devices('GPU') else \"CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c5751bdb-d6dd-4eb7-b0e9-fc7d05302a71",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneDNN Enabled: \n"
     ]
    }
   ],
   "source": [
    "print(\"OneDNN Enabled:\", tf.config.optimizer.get_jit())  # Should print True or None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4a56d5af-245d-4ad2-92b5-8df4e738da43",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available CPUs: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
     ]
    }
   ],
   "source": [
    "print(\"Available CPUs:\", tf.config.list_physical_devices('CPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "650f7ee1-b6c5-4c3c-8fd8-deff3582a073",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized TensorFlow settings for CPU\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Adjust based on available CPU cores\n",
    "tf.config.threading.set_inter_op_parallelism_threads(4)  # Controls operations running in parallel\n",
    "tf.config.threading.set_intra_op_parallelism_threads(4)  # Controls parallelism within individual operations\n",
    "\n",
    "print(\"Optimized TensorFlow settings for CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5d7c806e-26f6-4202-b89b-645ecfcfd0f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.tree import ExtraTreeRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator\n",
    "from scipy.stats import chi2\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier, ExtraTreeRegressor, ExtraTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, ExtraTreesRegressor, ExtraTreesClassifier, AdaBoostRegressor\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier, RadiusNeighborsClassifier\n",
    "\n",
    "from scipy.stats.mstats import winsorize\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import ExtraTreesRegressor, ExtraTreesClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") # Suppress all warnings\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cde5d525-a4d4-4ae5-920a-e85961d240ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authentication successful!\n"
     ]
    }
   ],
   "source": [
    "# Initialize BigQuery and Storage clients\n",
    "storage_client = storage.Client()\n",
    "client = bigquery.Client()\n",
    "storage_client = storage.Client()\n",
    "print(\"Authentication successful!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "27729e82-01de-4367-af42-516a38ece686",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table big-data-engin.Sample1.airplane1 created successfully.\n"
     ]
    }
   ],
   "source": [
    "project_id = \"big-data-engin\"  # Replace with your GCP project ID\n",
    "dataset_id = \"Sample1\"  # Replace with your BigQuery dataset ID\n",
    "table_id = \"airplane1\"    # Replace with your desired table name\n",
    "\n",
    "full_table_id = f\"{project_id}.{dataset_id}.{table_id}\"\n",
    "\n",
    "# Create an empty table with no schema\n",
    "table = bigquery.Table(full_table_id)\n",
    "table = client.create_table(table)\n",
    "print(f\"Table {full_table_id} created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "052d2af3-f450-412c-9f14-3faa47301723",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded CSV file into big-data-engin.Sample1.airplane1 successfully.\n"
     ]
    }
   ],
   "source": [
    "gcs_uri = \"gs://samplebucketvrs/Intelligence Analytics/og4/2019.csv\"  # Replace with your GCS path\n",
    "\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    source_format=bigquery.SourceFormat.CSV,\n",
    "    skip_leading_rows=1,  # Skips the header row\n",
    "    autodetect=True,  # Enables schema autodetection\n",
    "    write_disposition=\"WRITE_APPEND\",  # Append data if table already exists\n",
    ")\n",
    "\n",
    "load_job = client.load_table_from_uri(\n",
    "    gcs_uri, full_table_id, job_config=job_config\n",
    ")\n",
    "\n",
    "load_job.result()  # Wait for the job to complete\n",
    "print(f\"Loaded CSV file into {full_table_id} successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c86a6531-a955-4e26-b124-2ee39c176de5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FL_DATE</th>\n",
       "      <th>OP_UNIQUE_CARRIER</th>\n",
       "      <th>OP_CARRIER_FL_NUM</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>DEST</th>\n",
       "      <th>DEP_TIME</th>\n",
       "      <th>DEP_DELAY</th>\n",
       "      <th>TAXI_OUT</th>\n",
       "      <th>WHEELS_OFF</th>\n",
       "      <th>WHEELS_ON</th>\n",
       "      <th>...</th>\n",
       "      <th>ARR_TIME</th>\n",
       "      <th>ARR_DELAY</th>\n",
       "      <th>AIR_TIME</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>CARRIER_DELAY</th>\n",
       "      <th>WEATHER_DELAY</th>\n",
       "      <th>NAS_DELAY</th>\n",
       "      <th>SECURITY_DELAY</th>\n",
       "      <th>LATE_AIRCRAFT_DELAY</th>\n",
       "      <th>string_field_20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-04-04</td>\n",
       "      <td>AS</td>\n",
       "      <td>64</td>\n",
       "      <td>PSG</td>\n",
       "      <td>WRG</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-16</td>\n",
       "      <td>AS</td>\n",
       "      <td>64</td>\n",
       "      <td>PSG</td>\n",
       "      <td>WRG</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-03-28</td>\n",
       "      <td>AS</td>\n",
       "      <td>65</td>\n",
       "      <td>WRG</td>\n",
       "      <td>PSG</td>\n",
       "      <td>1019</td>\n",
       "      <td>-26.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>1026</td>\n",
       "      <td>1035</td>\n",
       "      <td>...</td>\n",
       "      <td>1038</td>\n",
       "      <td>-27.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>31.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-11-03</td>\n",
       "      <td>AS</td>\n",
       "      <td>64</td>\n",
       "      <td>PSG</td>\n",
       "      <td>WRG</td>\n",
       "      <td>1441</td>\n",
       "      <td>-34.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>1452</td>\n",
       "      <td>1503</td>\n",
       "      <td>...</td>\n",
       "      <td>1508</td>\n",
       "      <td>-27.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>31.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-10-04</td>\n",
       "      <td>AS</td>\n",
       "      <td>64</td>\n",
       "      <td>PSG</td>\n",
       "      <td>WRG</td>\n",
       "      <td>1453</td>\n",
       "      <td>-22.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1458</td>\n",
       "      <td>1511</td>\n",
       "      <td>...</td>\n",
       "      <td>1515</td>\n",
       "      <td>-20.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>31.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      FL_DATE OP_UNIQUE_CARRIER  OP_CARRIER_FL_NUM ORIGIN DEST  DEP_TIME  \\\n",
       "0  2019-04-04                AS                 64    PSG  WRG      <NA>   \n",
       "1  2019-01-16                AS                 64    PSG  WRG      <NA>   \n",
       "2  2019-03-28                AS                 65    WRG  PSG      1019   \n",
       "3  2019-11-03                AS                 64    PSG  WRG      1441   \n",
       "4  2019-10-04                AS                 64    PSG  WRG      1453   \n",
       "\n",
       "   DEP_DELAY  TAXI_OUT  WHEELS_OFF  WHEELS_ON  ...  ARR_TIME  ARR_DELAY  \\\n",
       "0        NaN       NaN        <NA>       <NA>  ...      <NA>        NaN   \n",
       "1        NaN       NaN        <NA>       <NA>  ...      <NA>        NaN   \n",
       "2     -26.00      7.00        1026       1035  ...      1038     -27.00   \n",
       "3     -34.00     11.00        1452       1503  ...      1508     -27.00   \n",
       "4     -22.00      5.00        1458       1511  ...      1515     -20.00   \n",
       "\n",
       "   AIR_TIME  DISTANCE  CARRIER_DELAY  WEATHER_DELAY  NAS_DELAY  \\\n",
       "0       NaN     31.00            NaN            NaN        NaN   \n",
       "1       NaN     31.00            NaN            NaN        NaN   \n",
       "2      9.00     31.00            NaN            NaN        NaN   \n",
       "3     11.00     31.00            NaN            NaN        NaN   \n",
       "4     13.00     31.00            NaN            NaN        NaN   \n",
       "\n",
       "   SECURITY_DELAY  LATE_AIRCRAFT_DELAY  string_field_20  \n",
       "0             NaN                  NaN             None  \n",
       "1             NaN                  NaN             None  \n",
       "2             NaN                  NaN             None  \n",
       "3             NaN                  NaN             None  \n",
       "4             NaN                  NaN             None  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = client.list_rows(table).to_dataframe()  # Download table contents into a DataFrame\n",
    "\n",
    "# Display the DataFrame\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "522f985b-9df3-4422-9e8f-9814793145e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.describe()\n",
    "columns_to_drop = [col for col in df.columns if col.lower() == 'id']\n",
    "\n",
    "if columns_to_drop:\n",
    "    df = df.drop(columns=columns_to_drop)\n",
    "# Convert the Date column to datetime\n",
    "df['FL_DATE'] = pd.to_datetime(df['FL_DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd26ca2-97ad-48bf-8dff-932bd28d2c4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def identify_column_type(df):\n",
    "    column_types = []\n",
    "    for col in df.columns:\n",
    "        if pd.api.types.is_bool_dtype(df[col]):  # Check for Boolean columns first\n",
    "            col_type = \"Boolean\"\n",
    "        elif pd.api.types.is_numeric_dtype(df[col]):  # Check for numeric columns\n",
    "            col_type = \"Numerical\"\n",
    "        elif pd.api.types.is_categorical_dtype(df[col]) or df[col].dtype == 'object':  # Check for categorical columns\n",
    "            col_type = \"Categorical\"\n",
    "        elif pd.api.types.is_datetime64_any_dtype(df[col]):  # Check for datetime columns\n",
    "            col_type = \"Datetime\"\n",
    "        else:\n",
    "            col_type = \"Unknown\"  # Any other type falls here\n",
    "        column_types.append({'Column': col, 'Type': col_type})\n",
    "    \n",
    "    # Convert the list of dictionaries to a DataFrame\n",
    "    column_types_df = pd.DataFrame(column_types)\n",
    "    return column_types_df\n",
    "\n",
    "# Identify column types\n",
    "column_types_df = identify_column_type(df)\n",
    "print(column_types_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f88e1b1-8db9-494d-9433-84ddc22dcb15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-tensorflow-tensorflow",
   "name": "workbench-notebooks.m127",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m127"
  },
  "kernelspec": {
   "display_name": "TensorFlow 2-11 (Local)",
   "language": "python",
   "name": "conda-env-tensorflow-tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
